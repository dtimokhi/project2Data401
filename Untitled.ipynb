{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "from sklearn import datasets\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(object):\n",
    "    \n",
    "    def __call__(self, predicted, actual):\n",
    "        \"\"\"Calculates the loss as a function of the prediction and the actual.\n",
    "        \n",
    "        Args:\n",
    "          predicted (np.ndarray, float): the predicted output labels\n",
    "          actual (np.ndarray, float): the actual output labels\n",
    "          \n",
    "        Returns: (float) \n",
    "          The value of the loss for this batch of observations.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def derivative(self, predicted, actual):\n",
    "        \"\"\"The derivative of the loss with respect to the prediction.\n",
    "        \n",
    "        Args:\n",
    "          predicted (np.ndarray, float): the predicted output labels\n",
    "          actual (np.ndarray, float): the actual output labels\n",
    "          \n",
    "        Returns: (np.ndarray, float) \n",
    "          The derivatives of the loss.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "              \n",
    "class SquaredErrorLoss(Loss):\n",
    "    #CHANGE THIS TO ** rather than np.square?\n",
    "    def __call__(self, predicted, actual):\n",
    "        return predicted-actual**2\n",
    "    def derivative(self, predicted, actual):\n",
    "        return 2*np.subtract(predicted, actual)\n",
    "    \n",
    "class ActivationFunction(object):\n",
    "        \n",
    "    def __call__(self, a):\n",
    "        \"\"\"Applies activation function to the values in a layer.\n",
    "        \n",
    "        Args:\n",
    "          a (np.ndarray, float): the values from the previous layer (after \n",
    "            multiplying by the weights.\n",
    "          \n",
    "        Returns: (np.ndarray, float) \n",
    "          The values h = g(a).\n",
    "        \"\"\"\n",
    "        return a\n",
    "    \n",
    "    def derivative(self, h):\n",
    "        \"\"\"The derivatives as a function of the outputs at the nodes.\n",
    "        \n",
    "        Args:\n",
    "          h (np.ndarray, float): the outputs h = g(a) at the nodes.\n",
    "          \n",
    "        Returns: (np.ndarray, float) \n",
    "          The derivatives dh/da.\n",
    "        \"\"\"\n",
    "        return 1\n",
    "       \n",
    "class ReLU(ActivationFunction):\n",
    "    def __call__(self, a):\n",
    "        return np.clip(a, 0, None)\n",
    "    def derivative(self, h):\n",
    "        return np.clip(h, 0, 1)\n",
    "\n",
    "class Sigmoid(ActivationFunction):\n",
    "    def __call__(self, a):\n",
    "        return 1.0/(1.0+np.exp(-a))\n",
    "    def derivative(self, h):\n",
    "        return self.__call__(h)*(1-self.__call__(h))\n",
    "    \n",
    "class Layer(object):\n",
    "    \"\"\"A data structure for a layer in a neural network.\n",
    "    \n",
    "    Attributes:\n",
    "      num_nodes (int): number of nodes in the layer\n",
    "      activation_function (ActivationFunction)\n",
    "      values_pre_activation (np.ndarray, float): most recent values\n",
    "        in layer, before applying activation function\n",
    "      values_post_activation (np.ndarray, float): most recent values\n",
    "        in layer, after applying activation function\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_nodes, activation_function=ActivationFunction()):\n",
    "        self.num_nodes = num_nodes\n",
    "        self.activation_function = activation_function\n",
    "        \n",
    "    def get_layer_values(self, values_pre_activation):\n",
    "        \"\"\"Applies activation function to values from previous layer.\n",
    "        \n",
    "        Stores the values (both before and after applying activation \n",
    "        function)\n",
    "        \n",
    "        Args:\n",
    "          values_pre_activation (np.ndarray, float): \n",
    "            A (batch size) x self.num_nodes array of the values\n",
    "            in layer before applying the activation function\n",
    "        \n",
    "        Returns: (np.ndarray, float)\n",
    "            A (batch size) x self.num_nodes array of the values\n",
    "            in layer after applying the activation function\n",
    "        \"\"\"\n",
    "        self.values_pre_activation = values_pre_activation\n",
    "        self.values_post_activation = self.activation_function(\n",
    "            values_pre_activation\n",
    "        )\n",
    "        return self.values_post_activation\n",
    "\n",
    "        \n",
    "class FullyConnectedNeuralNetwork(object):\n",
    "    \"\"\"A data structure for a fully-connected neural network.\n",
    "    \n",
    "    Attributes:\n",
    "      layers (Layer): A list of Layer objects.\n",
    "      loss (Loss): The loss function to use in training.\n",
    "      learning_rate (float): The learning rate to use in backpropagation.\n",
    "      weights (list, np.ndarray): A list of weight matrices,\n",
    "        length should be len(self.layers) - 1\n",
    "      biases (list, float): A list of bias terms,\n",
    "        length should be equal to len(self.layers)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layers, loss, learning_rate, epochs, batch_size):\n",
    "        self.layers = layers\n",
    "        self.loss = loss\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # initialize weight matrices and biases to zeros\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        for i in range(1, len(self.layers)):\n",
    "            self.weights.append(\n",
    "                np.random.normal(0, .05, (self.layers[i - 1].num_nodes, self.layers[i].num_nodes))\n",
    "            )\n",
    "            self.biases.append(\n",
    "                np.random.normal(0, .05, self.layers[i].num_nodes)\n",
    "            )\n",
    "    def reset(self):\n",
    "        self.__init__(self.layers, self.loss, self.learning_rate, self.epochs, self.batch_size)\n",
    "    \n",
    "    def feedforward(self, inputs):\n",
    "        \"\"\"Predicts the output(s) for a given set of input(s).\n",
    "        \n",
    "        Args:\n",
    "          inputs (np.ndarray, float): A (batch size) x self.layers[0].num_nodes array\n",
    "          \n",
    "        Returns: (np.ndarray, float) \n",
    "          An array of the predicted output labels, length is the batch size\n",
    "        \"\"\"\n",
    "        # TODO: Implement feedforward prediction.\n",
    "        # Make sure you use Layer.get_layer_values() at each layer to store the values\n",
    "        # for later use in backpropagation.\n",
    "\n",
    "        h = self.layers[0].get_layer_values(inputs)\n",
    "        for i in range(1, len(self.layers)):\n",
    "            b = self.biases[i-1]\n",
    "            w = self.weights[i-1]\n",
    "            z = np.matmul(h, w) + b\n",
    "            h = self.layers[i].get_layer_values(z)\n",
    "        return h\n",
    "        \n",
    "    def backprop(self, predicted, actual):\n",
    "        \"\"\"Updates self.weights and self.biases based on predicted and actual values.\n",
    "        \n",
    "        This will require using the values at each layer that were stored at the\n",
    "        feedforward step.\n",
    "        \n",
    "        Args:\n",
    "          predicted (np.ndarray, float): An array of the predicted output labels\n",
    "          actual (np.ndarray, float): An array of the actual output labels\n",
    "        \"\"\"\n",
    "        \n",
    "        w_new = [np.zeros(w.shape) for w in self.weights]\n",
    "        b_new = [np.zeros(b.shape) for b in self.biases]\n",
    "        n = len(predicted)\n",
    "        if(n == 1):\n",
    "            delta = self.loss.derivative(predicted, actual)\n",
    "            b_new[-1] = self.biases[-1] - self.learning_rate * delta.T\n",
    "            w_new[-1] = self.weights[-1] - self.learning_rate * np.dot(delta, self.layers[-2].values_post_activation).T\n",
    "            for i in range(2, len(self.layers)):\n",
    "                a = (self.layers[-i].values_pre_activation)\n",
    "                h = (self.layers[-i-1].values_post_activation)\n",
    "                g_prime = (self.layers[-i].activation_function.derivative(a)).T\n",
    "                delta = np.multiply(np.dot(self.weights[-i+1], delta), g_prime)\n",
    "                b_new[-i] = self.biases[-i] - self.learning_rate * delta.T\n",
    "                w_new[-i] = self.weights[-i] - self.learning_rate * np.dot(delta, h).T\n",
    "        else:\n",
    "            delta = np.array([self.loss.derivative(predicted.flatten(), actual)])\n",
    "            b_new[-1] = self.biases[-1] - self.learning_rate/n * np.array([np.sum(delta, axis=1)])\n",
    "            w_new[-1] = self.weights[-1] - self.learning_rate/n * np.dot(delta, self.layers[-2].values_post_activation).T\n",
    "            for i in range(2, len(self.layers)):\n",
    "                a = (self.layers[-i].values_pre_activation)\n",
    "                h = (self.layers[-i-1].values_post_activation)\n",
    "                g_prime = (self.layers[-i].activation_function.derivative(a)).T\n",
    "                delta = np.multiply(np.dot(self.weights[-i+1], delta), g_prime)\n",
    "                b_new[-i] = self.biases[-i] - self.learning_rate/n * np.array([np.sum(delta, axis=1)])\n",
    "                w_new[-i] = self.weights[-i] - self.learning_rate/n * np.dot(delta, h).T\n",
    "            \n",
    "        self.weights = w_new\n",
    "        self.biases = b_new\n",
    "\n",
    "        \n",
    "    def train(self, inputs, labels, epochs=-1, batch_size=-1, verbose=True):\n",
    "        \"\"\"Trains neural network based on a batch of training data.\n",
    "        \n",
    "        Args:\n",
    "          inputs (np.ndarray): A (batch size) x self.layers[0].num_nodes array\n",
    "          labels (np.ndarray): An array of ground-truth output labels, \n",
    "            length is the batch size.\n",
    "        \"\"\"\n",
    "        if(epochs == -1):\n",
    "            epochs = self.epochs\n",
    "        if(batch_size == -1):\n",
    "            batch_size = self.batch_size\n",
    "        n = len(labels)\n",
    "        mse = []\n",
    "        for j in range(epochs):\n",
    "            mse = []\n",
    "            X, y = shuffle(inputs, labels)\n",
    "            for i in range(0, n, batch_size):\n",
    "                end = i+batch_size\n",
    "                predicted = self.feedforward(X[i:end])\n",
    "                mse.append(np.mean((y[i:end] - predicted)**2))\n",
    "                if(verbose):\n",
    "                    self.backprop(predicted, y[i:end])\n",
    "                    clear_output(wait=True)\n",
    "                    display(\"Epoch: {}/{} - {:>5}/{:5} - loss: {:.4f}\".format(j+1, epochs, (min(i+128, n)), n, np.mean(mse)))\n",
    "        return np.mean(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['review/appearance', 'review/aroma', 'review/overall', 'review/palate', 'review/taste', 'isdst'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['review/overall'].values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# X = full_data[['avg_palate', 'avg_aroma', 'avg_overall', 'avg_taste', 'avg_appear']].value\n",
    "X = df.drop(['review/appearance', 'review/aroma', 'review/overall', 'review/palate', 'review/taste', 'avg_palate', 'avg_aroma', 'avg_overall', 'avg_appear', 'avg_taste'], axis=1).values\n",
    "y = df['review/overall'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(network, X, y, k=10):\n",
    "    n = len(y)\n",
    "    step = n//k + 1\n",
    "    scores = []\n",
    "    for i in range(k):\n",
    "        mask = np.ones(len(y), dtype=bool)\n",
    "        split = i*step\n",
    "        idx = np.arange(split, min(n, split+step), 1)\n",
    "        mask[idx] = False\n",
    "        X_train = X[mask]\n",
    "        y_train = y[mask]\n",
    "        X_test = X[idx]\n",
    "        y_test = y[idx]\n",
    "        network.train(X_train, y_train)\n",
    "        predicted = network.feedforward(X_test)\n",
    "        scores.append(np.mean((y_test - predicted)**2))\n",
    "        network.reset()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28113/28113 [==============================] - 2s 81us/step - loss: 0.9180\n",
      "Epoch 2/5\n",
      "28113/28113 [==============================] - 2s 75us/step - loss: 0.4592\n",
      "Epoch 3/5\n",
      "28113/28113 [==============================] - 2s 75us/step - loss: 0.4343\n",
      "Epoch 4/5\n",
      "28113/28113 [==============================] - 2s 69us/step - loss: 0.4272\n",
      "Epoch 5/5\n",
      "28113/28113 [==============================] - 2s 69us/step - loss: 0.4239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1ff7b0be10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify the model architecture\n",
    "# l = [layers.Dense(896, activation=\"relu\")] + ([layers.Dense(20, activation=\"relu\")] * 20) + [layers.Dense(1)]\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(891, kernel_initializer='random_normal', bias_initializer='random_normal'),\n",
    "    layers.Dense(448, activation=\"relu\", kernel_initializer='random_normal', bias_initializer=\n",
    "                 'random_normal'),\n",
    "#     layers.Dense(224, activation=\"relu\"),\n",
    "#     layers.Dense(112, activation=\"relu\"),\n",
    "#     layers.Dense(56, activation=\"relu\"),\n",
    "#     layers.Dense(28, activation=\"relu\"),\n",
    "#     layers.Dense(14, activation=\"relu\"),\n",
    "#     layers.Dense(7, activation=\"relu\"),\n",
    "#     layers.Dense(3, activation=\"relu\"),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# specify the loss function and optimization function\n",
    "model.compile(optimizer=tf.train.GradientDescentOptimizer(0.0001),\n",
    "              loss='mse')\n",
    "\n",
    "# fit the model to data\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68660514001673578"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((y_test - model.predict(X_test))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = FullyConnectedNeuralNetwork(\n",
    "    layers=[Layer(895), Layer(448, ReLU()), Layer(5)],\n",
    "    loss = SquaredErrorLoss(),\n",
    "    learning_rate= 0.0001,\n",
    "    epochs = 10,\n",
    "    batch_size = 128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = FullyConnectedNeuralNetwork(\n",
    "    layers=[Layer(895), Layer(448, ReLU()), Layer(1)],\n",
    "    loss = SquaredErrorLoss(),\n",
    "    learning_rate= 0.0001,\n",
    "    epochs = 10,\n",
    "    batch_size = 128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Epoch: 10/10 - 29988/29988 - loss: 0.8016'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.78463018326620249"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 2\n",
    "net_layers = [Layer(895)]\n",
    "for i in range(n):\n",
    "    net_layers.append(Layer(895, ReLU()))\n",
    "net_layers.append(Layer(1))\n",
    "network = FullyConnectedNeuralNetwork(\n",
    "    layers=net_layers,\n",
    "    loss = SquaredErrorLoss(),\n",
    "    learning_rate= 0.00001,\n",
    "    epochs = 10,\n",
    "    batch_size = 128\n",
    ")\n",
    "scores = cross_validate(network, X, y, k=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Layer at 0x7fced2cc9dd8>,\n",
       " <__main__.Layer at 0x7fced2cc9e10>,\n",
       " <__main__.Layer at 0x7fced2cc9e10>,\n",
       " <__main__.Layer at 0x7fced2cc9e48>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Epoch: 1/10 - 12800/29987 - loss: 1.6672'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-0104cc1e8b7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     )\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mnum_node_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-88065afe1d89>\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(network, X, y, k)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-2addf3937a69>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, inputs, labels, epochs, batch_size, verbose)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0mmse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch: {}/{} - {:>5}/{:5} - loss: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-2addf3937a69>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(self, predicted, actual)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_prime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0mb_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m                 \u001b[0mw_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nodes = np.arange(1, 6, 1)\n",
    "num_node_scores = []\n",
    "for n in nodes:\n",
    "    network = FullyConnectedNeuralNetwork(\n",
    "        layers=[Layer(895), Layer(n, ReLU()), Layer(1)],\n",
    "        loss = SquaredErrorLoss(),\n",
    "        learning_rate= 0.0001,\n",
    "        epochs = 10,\n",
    "        batch_size = 128\n",
    "    )\n",
    "    scores = cross_validate(network, X, y, k=5)\n",
    "    num_node_scores.append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_node_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1fbc92b400>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl4VeW99vHvLzMJUwJhDHOCiooMYVYZ6oDWOqIFrYoTFsH32NN6jrZv37ae9nQ8PR1kEBWHVnFABGxrsVVAZBASGWSKJIQhRCCMgUDm5/1jL2yMgQRIsvbOvj/XlYu9137CvldWcmflWWvvZc45REQkPET4HUBERBqPSl9EJIyo9EVEwohKX0QkjKj0RUTCiEpfRCSMqPRFRMKISl9EJIyo9EVEwkiU3wGqa9u2revevbvfMUREQkpmZuYB51xybeOCrvS7d+9ORkaG3zFEREKKme2syzhN74iIhBGVvohIGFHpi4iEkTqVvpmNNbMsM8s2sydqePx/zWyd9/GZmR2p8ti9ZrbN+7i3PsOLiMjZqfVArplFAtOAq4E8YI2ZLXTObT41xjn3nSrjHwX6e7eTgB8B6YADMr3PPVyvayEiInVSlz39wUC2c267c64UeA246QzjJwBzvNvXAv9wzh3yiv4fwNjzCSwiIueuLqXfGdhd5X6et+wrzKwb0AP44Gw/V0REGl5dSt9qWHa6ayyOB+Y65yrO5nPNbJKZZZhZRkFBQR0ifdXRk2X8z3tZZO8/fk6fLyISDupS+nlAlyr3U4D804wdz7+mdur8uc65Wc65dOdcenJyrS8oq1F5RSXPLtvOjCU55/T5IiLhoC6lvwZIM7MeZhZDoNgXVh9kZhcAicDKKosXAdeYWaKZJQLXeMvqXZvmsUwY3JX56/aw+9CJhngKEZGQV2vpO+fKgakEynoL8IZzbpOZPWVmN1YZOgF4zTnnqnzuIeC/CPziWAM85S1rEJOu7EmkGTOXam9fRKQmVqWjg0J6ero7n/feeXLep7yVmcey/xxN+5Zx9ZhMRCR4mVmmcy69tnFN7hW5k0f2osI5Zn243e8oIiJBp8mVftc28dx0WSde/XgXB4+X+B1HRCSoNLnSB3hkdC+KyyuYvTzX7ygiIkGlSZZ+arsWXHdJB15esZOjJ8v8jiMiEjSaZOkDTBmdyrGScl5escPvKCIiQaPJlv7FnVox5sJ2zF6eS1FJud9xRESCQpMtfQjs7R8+UcarH+/yO4qISFBo0qU/sFsiw3u1Yday7RSXVdT+CSIiTVyTLn2AqWNSKThWwpuZeX5HERHxXZMv/WE92zCga2tmLsmhrKLS7zgiIr5q8qVvZkwdk8qeIyeZv3aP33FERHzV5EsfYPQF7ejTsSXTl+RQURlc7zUkItKYwqL0T+3t5x4o4m+ffu53HBER34RF6QOMvbgDqe2aM21xNpXa2xeRMBU2pR8RYTwyqhdb9x7j/a37/Y4jIuKLsCl9gBsv60SXpGY8/cE2gu06AiIijSGsSj8qMoLJI1NZn3eUj7IP+B1HRKTRhVXpA9w2sDMdWsbxxw+y/Y4iItLowq70Y6MimXRlT1bnHmLNjga7XK+ISFAKu9IHmDC4K20SYnhae/siEmbCsvSbxUTywBU9WPpZARvyjvgdR0Sk0YRl6QPcPbQbLeOimLZYe/siEj7CtvRbxEUzcUQPFm3aR9beY37HERFpFGFb+gD3De9OfEwk05dob19EwkNYl35iQgx3D+3GO+vz2XGgyO84IiINLqxLH+CBK3oQFRnBjCU5fkcREWlwYV/67VrEMWFQF976JI89R076HUdEpEGFfekDTBrZC4BZS7W3LyJNm0of6Ny6GbcNSGHOmt3sP1bsdxwRkQZTp9I3s7FmlmVm2Wb2xGnG3GFmm81sk5m9WmX5L81so/fxzfoKXt8mj+pFeUUlzy/L9TuKiEiDqbX0zSwSmAZcB/QBJphZn2pj0oAngRHOuYuBx7zlXwcGAP2AIcDjZtayXtegnnRvm8A3LuvEn1ft5HBRqd9xREQaRF329AcD2c657c65UuA14KZqYx4CpjnnDgM4505dpaQPsNQ5V+6cKwLWA2PrJ3r9e2RUKkWlFbywYoffUUREGkRdSr8zsLvK/TxvWVW9gd5mttzMVpnZqWJfD1xnZvFm1hYYDXQ539AN5YIOLbj24va8uDyXY8VlfscREal3dSl9q2FZ9ctORQFpwChgAvCcmbV2zr0H/A1YAcwBVgLlX3kCs0lmlmFmGQUFBWcRv/5NHZ1GYXE5f1q109ccIiINoS6ln8eX985TgPwaxixwzpU553KBLAK/BHDO/cw51885dzWBXyDbqj+Bc26Wcy7dOZeenJx8LutRby5NacWVvZN5flkuJ0srfM0iIlLf6lL6a4A0M+thZjHAeGBhtTHzCUzd4E3j9Aa2m1mkmbXxlvcF+gLv1Vf4hvLomFQOFpUyZ/Uuv6OIiNSrWkvfOVcOTAUWAVuAN5xzm8zsKTO70Ru2CDhoZpuBxcDjzrmDQDSwzFs+C/iW9/8FtUHdkxjcI4lZH26npFx7+yLSdJhz1afn/ZWenu4yMjL8jsGybQXc/fxq/vuWS7lzSFe/44iInJGZZTrn0msbp1fknsblqW25LKUVM5fmUF5R6XccEZF6odI/DTNj6pg0dh06wTsbqh+3FhEJTSr9M/jahe24sEMLpi3OobIyuKbBRETOhUr/DCIijCmjU8nef5xFm/b6HUdE5Lyp9Gtx/aUd6dk2gacXZxNsB71FRM6WSr8WkRHG5FG92JRfyJIsf18tLCJyvlT6dXBz/850bt2MP36wTXv7IhLSVPp1EB0ZwbdH9eKTXUdYuf2g33FERM6ZSr+Obh+YQrsWsTz9QbbfUUREzplKv47ioiN56IqerMg5SObOw37HERE5Jyr9s3DnkK4kxkczbbH29kUkNKn0z0JCbBT3j+jBB1v3syn/qN9xRETOmkr/LN0zvDstYqOYvjjH7ygiImdNpX+WWjWL5p7h3fjbxs/J3n/M7zgiImdFpX8O7h/Rg7ioSKYv0d6+iIQWlf45aNM8ljuHdGXBunx2HTzhdxwRkTpT6Z+jSVf2JNKMmR9qb19EQodK/xy1bxnH7ekpzM3IY+/RYr/jiIjUiUr/PHx7ZC8qnGPWh9v9jiIiUicq/fPQJSmem/t15tXVOzlwvMTvOCIitVLpn6dHRveipLyS2R/l+h1FRKRWKv3z1Cu5Oddf2pGXV+7k6Ikyv+OIiJyRSr8eTBmVyvGScl5aucPvKCIiZ6TSrwd9OrXkqovaMXt5LkUl5X7HERE5LZV+PZkyOpUjJ8p45eOdfkcRETktlX496d81kctT2/LsslyKyyr8jiMiUiOVfj2aMjqVgmMlvJGx2+8oIiI1UunXo6E9k0jvlsgzS7dTWl7pdxwRka9Q6dcjM2PKmFT2HDnJ/LV7/I4jIvIVKv16Nqp3Mpd0bsn0JdlUVDq/44iIfEmdSt/MxppZlpllm9kTpxlzh5ltNrNNZvZqleW/8pZtMbM/mJnVV/hgZGZMHZ3KjoMn+MuGfL/jiIh8Sa2lb2aRwDTgOqAPMMHM+lQbkwY8CYxwzl0MPOYtHw6MAPoClwCDgJH1uQLB6Jo+HUhr15zpi3Oo1N6+iASRuuzpDwaynXPbnXOlwGvATdXGPARMc84dBnDO7feWOyAOiAFigWhgX30ED2YREcaU0alk7TvGP7Y0+dUVkRBSl9LvDFQ9BzHPW1ZVb6C3mS03s1VmNhbAObcSWAx87n0scs5tqf4EZjbJzDLMLKOgoOBc1iPo3NC3I93axDNtcTbOaW9fRIJDXUq/pjn46i0WBaQBo4AJwHNm1trMUoGLgBQCvyjGmNmVX/nPnJvlnEt3zqUnJyefTf6gFRUZweSRvdiQd5Rl2w74HUdEBKhb6ecBXarcTwGqH6HMAxY458qcc7lAFoFfArcAq5xzx51zx4F3gaHnHzs03DoghY6t4nj6g2y/o4iIAHUr/TVAmpn1MLMYYDywsNqY+cBoADNrS2C6ZzuwCxhpZlFmFk3gIO5XpneaqpioCB6+sierdxzi4+0H/Y4jIlJ76TvnyoGpwCIChf2Gc26TmT1lZjd6wxYBB81sM4E5/MedcweBuUAO8CmwHljvnHunAdYjaI0f3JW2zWN4erH29kXEfxZsBxnT09NdRkaG3zHq1cylOfzi3a0smDKCy7q09juOiDRBZpbpnEuvbZxekdsIvjW0G62aRWtvX0R8p9JvBM1jo7hvRHf+sXkfW/cW+h1HRMKYSr+RTBzenYSYSKYtzvE7ioiEMZV+I2kdH8Pdw7rz1w355B4o8juOiIQplX4jeuDyHkRHRjBjieb2RcQfKv1GlNwilgmDuzLvkz3kHT7hdxwRCUMq/Ub28MiemMGsD7f7HUVEwpBKv5F1bNWMcQNTeG3NbvYXFvsdR0TCjErfB98e2Yvyikqe+yjX7ygiEmZU+j7o1iaBGy/rxJ9X7eRwUanfcUQkjKj0fTJldConSit4Ybn29kWk8aj0fZLWvgVjL+7ACyt2UFhc5nccEQkTKn0fTR2TyrHicv60cqffUUQkTKj0fXRJ51aMuiCZ5z/K5URpud9xRCQMqPR99uiYVA4VlTJn9e7aB4uInCeVvs8GdktiaM8kZn2YQ0l5hd9xRKSJU+kHgUfHpLGvsIS5mXl+RxGRJk6lHwSG92pDvy6tmbEkh7KKSr/jiEgTptIPAmbGo2NSyTt8koXr8v2OIyJNmEo/SIy5sB0XdWzJ9CXZVFQG13WLRaTpUOkHCTNj6uhUcgqK+PvGvX7HEZEmSqUfRMZe0oGeyQk8vTgb57S3LyL1T6UfRCIjjEdGpbLl80I+2Lrf7zgi0gSp9IPMTf06kZLYjD9+oL19Eal/Kv0gEx0ZwbdH9mLd7iOsyDnodxwRaWJU+kFo3MAU2reM5ekPdAF1EalfKv0gFBcdyUNX9GTl9oNk7jzkdxwRaUJU+kHqziFdSUqI0d6+iNQrlX6Qio+J4oHLe7A4q4CNe476HUdEmog6lb6ZjTWzLDPLNrMnTjPmDjPbbGabzOxVb9loM1tX5aPYzG6uzxVoyu4e1o0WcVFMW6y9fRGpH1G1DTCzSGAacDWQB6wxs4XOuc1VxqQBTwIjnHOHzawdgHNuMdDPG5MEZAPv1ftaNFEt46KZOLw7Ty/OZtu+Y6S1b+F3JBEJcXXZ0x8MZDvntjvnSoHXgJuqjXkImOacOwzgnKvplUXjgHedcyfOJ3C4uW9ED5pFRzJ9SY7fUUSkCahL6XcGql7WKc9bVlVvoLeZLTezVWY2tob/Zzwwp6YnMLNJZpZhZhkFBQV1yR02khJiuGtIVxauz2fnwSK/44hIiKtL6VsNy6q/VDQKSANGAROA58ys9Rf/gVlH4FJgUU1P4Jyb5ZxLd86lJycn1yV3WHnoip5ERhgzl2pvX0TOT11KPw/oUuV+ClD9Td/zgAXOuTLnXC6QReCXwCl3AG8758rOJ2y4atcyjm+md2FuZh6fHz3pdxwRCWF1Kf01QJqZ9TCzGALTNAurjZkPjAYws7YEpnu2V3l8AqeZ2pG6eXhkT5yDWR9ur32wiMhp1Fr6zrlyYCqBqZktwBvOuU1m9pSZ3egNWwQcNLPNwGLgcefcQQAz607gL4Wl9R8/fKQkxnNL/87MWb2LA8dL/I4jIiHKgu2dHNPT011GRobfMYLS9oLjXPXbpTw8shf/OfZCv+OISBAxs0znXHpt4/SK3BDSM7k5X+/biT+t3MnREzo8IiJnT6UfYqaM7sXxknJeXLHD7ygiEoJU+iHmwg4tubpPe2Yvz+V4SbnfcUQkxKj0Q9DU0akcPVnGK6t2+h1FREKMSj8EXdalNVekteXZZbkUl1X4HUdEQohKP0RNHZ3KgeMlvL5md+2DRUQ8Kv0QNaRnGwZ3T2Lm0hxKyyv9jiMiIUKlH8Ie/Voqnx8t5tE5n2iaR0TqRKUfwq5IS+ZH3+jDe5v3MeHZVRzUK3VFpBYq/RB334gezLhrAJvzC7ltxgp2HNDbL4vI6an0m4Cxl3Tk1YeGcvRkGbfOWMEnuw77HUlEgpRKv4kY2C2ReY+MoEVcFBNmreLvG/f6HUlEgpBKvwnp0TaBeZOHc1HHlkx+JZMXl+f6HUlEgoxKv4lp0zyWOQ8N5aqL2vPjdzbzs79uprIyuN5JVUT8o9JvgprFRDLzWwO5d1g3nl2Wy6Nz1uqUThEBAte2lSYoMsL48Y0Xk5IYz8/+toV9hcU8e086iQkxfkcTER9pT78JMzMeurIn0+4cwIY9R7lt5gp2HTzhdywR8ZFKPwx8vW9HXnlwCIeKSrl1xnLW7z7idyQR8YlKP0wM6p7EW5OHExcdyfhZq3h/yz6/I4mID1T6YaRXcnPefmQEae2b89DLGfxZ78cvEnZU+mEmuUUsr00ayugL2vF/52/kF+9u1SmdImFEpR+G4mOieObugdw1pCszl+bw2OvrKCnXKZ0i4UCnbIapqMgIfnrzJaQkxvPLv29lX2Exs+5Op1V8tN/RRKQBaU8/jJkZk0f14vfj+7F21xFum7mCvMM6pVOkKVPpCzf168zLDwxmf2Ext0xfwcY9R/2OJBJ2nHOUVTT8VfBU+gLA0J5tmDt5ODGREdzxzEoWZ+33O5JI2CirqOTJeZ/y72+sb/ATK1T68oXe7Vsw75Hh9GibwIMvZfDa6l1+RxJp8o4Vl/HASxm8tmY33dvEY9awz6fSly9p3zKO1x8exuWpbXli3qf8z3tZOKdTOkUawudHT3L7zJWsyD7Ar27ry3evuQBr4NZX6ctXNI+N4rl70xk/qAt//CCb776xntLyhp9rFAknWz4v5JZpK8g7fJLZEwdxx6AujfK8dSp9MxtrZllmlm1mT5xmzB1mttnMNpnZq1WWdzWz98xsi/d49/qJLg0pOjKCn996Kd+7pjfz1u5h4gurKSwu8zuWSJPw4WcF3D5zJQBvfnsYV/ZObrTnrrX0zSwSmAZcB/QBJphZn2pj0oAngRHOuYuBx6o8/DLwa+fcRcBgQEcIQ4SZMXVMGr+94zJW5x7i9hkryT9y0u9YIiHtjTW7ue/FNXRJimf+lBFc1LFloz5/Xfb0BwPZzrntzrlS4DXgpmpjHgKmOecOAzjn9gN4vxyinHP/8JYfd87pRPAQc+uAFF66fzD5R05yy/TlbM4v9DuSSMhxzvGbRVn8x1sbGJHaljceHkqHVnGNnqMupd8Z2F3lfp63rKreQG8zW25mq8xsbJXlR8xsnpmtNbNfe385SIgZkdqWNycPwzDueGYly7YV+B1JJGSUlFfwndfX8fTibMYP6sLz96bTIs6fV7/XpfRrOpRc/XSOKCANGAVMAJ4zs9be8iuA7wGDgJ7AxK88gdkkM8sws4yCApVJsLqwQ0venjKclMRm3PfCGt7M2F37J4mEuaMnyrh39mrmr8vn8Wsv4Oe3Xkp0pH/n0NTlmfOAqoeVU4D8GsYscM6VOedygSwCvwTygLXe1FA5MB8YUP0JnHOznHPpzrn05OTGO6AhZ69jq2a8+e1hDOvVhsfnbuB3//xMp3SKnMbuQye4beYKPtl5hN+P78eU0akNfkpmbepS+muANDPrYWYxwHhgYbUx84HRAGbWlsC0znbvcxPN7FSTjwE210dw8U+LuGhmTxzEbQNS+N0/t/Efczc0ysvHRULJhrwj3DJ9BfsLi3n5gcHc1K/6rLg/an2XTedcuZlNBRYBkcBs59wmM3sKyHDOLfQeu8bMNgMVwOPOuYMAZvY94H0L/HrLBJ5toHWRRhQdGcFvbu9L58Rm/OH9bewtLGb6XQN8m6cUCSb/3LyPR+espU3zGF6bNITUdi38jvQFC7Y/zdPT011GRobfMeQsvLFmN0++/Sm927fghYmDfDkjQSRYvLRiBz95ZxOXdm7Fc/cOIrlFbKM8r5llOufSaxunV+TKebtjUBdmTxzEroNF3DJ9OVl7j/kdSaTRVVY6fvqXzfxo4Sa+dlF75kwa2miFfzZU+lIvRvZO5o1vD6Oi0jFu5gpWZB/wO5JIoykuq2DKq5/w3Ee5TBzenZnfGkh8THBeo0qlL/Xm4k6teHvKCDq2iuPeF1bz9to8vyOJNLiDx0u489lV/H3TXn54Qx9+fOPFREb4e4bOmaj0pV51bt2MN789nPRuSXzn9fU8/cE2ndIpTVbugSJunbGCTfmFzLhrAA9c3sPvSLVS6Uu9a9UsmhfvH8TN/Trxm/c+4/tvf0q5TumUJiZjxyFunb6cY8XlzJk0lLGXdPQ7Up0E56SThLzYqEj+95v96JzYjGmLc/j8aDHT7hxAQqy+5ST0/XXD53znjXV0bt2MF+8bRLc2CX5HqjPt6UuDMTMev/ZC/vuWS1m27QDfnLWS/ceK/Y4lcs6cczyzNIcpr35C386tmDd5eEgVPqj0pRHcOaQrz92TzvaCIm6ZtoLs/TqlU0JPeUUlP1ywkZ+/u5Wv9+3Inx8cQmJCjN+xzppKXxrF6Avb8fqkYZSUV3Lr9BV8vP2g35FE6qyopJxJf8rkz6t28fDInvxxfH/iokPzDYNV+tJoLk1pxduPDCe5RSx3P7+aheurv2+fSPDZX1jMN2etZEnWfn568yU8ed1FRATxKZm1UelLo+qSFM9bk4fTr0tr/s+ctcxcmqNTOiVofbbvGLdMX8H2giKev3cQ3xraze9I502lL42udXwMLz8wmBv6duQX727lhws26pROCTorsg9w24wVlFVU8sbDwxh9YTu/I9ULnT8nvoiLjuQP4/vTObEZzyzdzt6jxfxhQv+gfem6hJe3MvN4Yt4GerRN4IX7BtO5dTO/I9Ub7emLbyIijCevu4inbrqYD7buZ8KsVRQcK/E7loQx5xy//+c2vvvmegb3SGLu5OFNqvBBpS9B4J5h3Xnm7nSy9h3j1hnLySk47nckCUOl5ZU8PncD//vPz7htQAovTBxMyyZ4fQiVvgSFq/u057VJwzhRUsFtM1aQseOQ35EkjBQWl3H/i2uYm5nHY1el8Zvb+xIT1TTrsWmulYSkfl1aM++R4STGx3Dncx/zt08/9zuShIH8Iye5fcZKVm0/yG9uv4zHrurt+3VsG5KOmklQ6dYmgbcmD+ehlzOY8uon/OD6i3jg8h5N+oewpLyCw0VlHCoq5fCJUg4WlXK4qJRDpz5OlBJpxtf7dmT0Be2a7B6oHzbuOcr9L67hZGkFL90/mBGpbf2O1OBU+hJ0khJieOXBIXzn9XX89K9byDt8kh/e0Ceo36P8lMpKR2FxWY3FfbioSqGfKONQUQmHi8o4XlJ+2v+vVbNo2iTEUFhcxsL1+SQlxHBzv86MG5hCn04tG3HNmp7FWfuZ+sontGoWzdzJw7mgQ/Bcx7YhqfQlKMVFRzLtzgH87G9beP6jXD4/epLf+/DS95OlFRw6Ucqh4zUV95eXn9pTrzzNa81ioyJokxBDUvMYEuNj6N4mnqSEGJLiY0hMiKFNQuDfJO+jdbNooiIDe/XlFZV8uK2AuZl5/HnVTmYvz6VPx5aMG5jCTf060aZ58F2WL5i9+vEufrhgIxd2aMHsiYNo3zJ8ruusC6NL0Jv9US7/9dfN9OvSmufuST/ngiuvqOTIybIzFvdBr7gPF5VxsKiE4rKaXzQWYZAYX6Wkv1Lc0SQlxHrLo2mTEEuzmPr5hXW4qJSF6/OZm5nHp3uOEh1pjLmwHeMGdmHUBclER2r653QqKx2/fi+LGUtyGH1BMk83obf7ruuF0VX6EhLe/fRzHnt9HR1bxfHifYPp1iae4yXlgbnwE6UcKirhUFENhV7l9tGTZZzu2715bBSJCdEkxQdKPNEr8qTmNRR6fAytmkUHxfuvbN1byFuZeby9dg8HjpfSJiGGm/t35vb0FC7soOmfqorLKnh87gbeWZ/PXUO68pMbL/7iL6mmQKUvTU7mzkM8+FIGRaUV4KD0NG/dEB1pJMb/a5rkiwKvcr9NQswXYxIToomNCs13TDylrKKSpVmB6Z/3t+6jrMJxSeeWjBuQwo39OpMUgm8BXJ8OF5Uy6U8ZrNlxmCeuu5CHr+zZ5E4OUOlLk5R7oIiXVuwgNjriS8VdtdBbxEY1uR/os3GoqJSF6/bwZmYem/ILiY40rrqoPeMGpjCyd3KT2ruti10HTzDxhdXkHTnJb++4jBv6dvI7UoNQ6YsIm/MLeeuTPOav3cPBolLaNo/llv6dGDewS1icrbJ212EefCmDCud49p50BnVP8jtSg1Hpi8gXyioqWZJVwNzM3by/ZT/llY6+Ka0YNzCFGy/rROv4pjf98/eNe3ns9bW0axHHi/cNomdyc78jNSiVvojU6ODxEhasC5z9s/nzQmIiI7iqTztuH9iFK9LaNonpn+c/yuWn9XDGVyhR6YtIrTblH2VuZh4L1uVzqKiU5Bax3No/8OKvtPahN/1TUen4r79s5sUVOxh7cQd+N75fyF7W8Gyp9EWkzkrLK1mctZ+5mXks3hqY/rmsS+vA9E/fTrSKD/53mzxZWsG/vbaW9zbv44HLe/D96y8KiVdx15d6LX0zGwv8HogEnnPO/aKGMXcAPwYcsN45d6e3vAL41Bu2yzl345meS6Uv4q8Dx0uYv3YPczPz2Lr3GDFREVzdpz23D0zhirTkoCzSA8dLeOClDDbkHeFHN/Rh4ogefkdqdPVW+mYWCXwGXA3kAWuACc65zVXGpAFvAGOcc4fNrJ1zbr/32HHnXJ2PoKj0RYKDc45N+YXe9M8eDp8oo33LWG7pn8K4gSmktguOA6M5BceZ+MJqCo6V8Ifx/bnm4g5+R/JFfZb+MODHzrlrvftPAjjnfl5lzK+Az5xzz9Xw+Sp9kRBXUl7B4q3e9E9WARWVjv5dA9M/N/TtRKtm/kz/fLz9IJP+lEl0pPHcvYPo16W1LzmCQV1Lvy5vOtEZ2F3lfh4wpNqY3t6TLicwBfRj59zfvcfizCwDKAd+4ZybX4fnFJEgEhsVydhLOjL2ko4UHAtM/7yZuZsfvL2Rn7yzmWsv7sC4gSlcntq20aZ/Fqzbw+NvbiAlqRkv3TeYLklxf78EAAAISElEQVTxjfK8oa4upV/TFqz+50EUkAaMAlKAZWZ2iXPuCNDVOZdvZj2BD8zsU+dczpeewGwSMAmga9euZ7kKItKYklvE8tCVPXnwih5s3FPI3MzdLFifzzvr8+nQMo5bB3TmtoEp9Gqg8+Kdc0xfksOvF2UxpEcSz9w9sEm+zqCh1KX084AuVe6nAPk1jFnlnCsDcs0si8AvgTXOuXwA59x2M1sC9Ae+VPrOuVnALAhM75zDeohIIzMzLk1pxaUprfj+1y/i/S2B6Z9nPtzO9CU5DOjamtvTu/D1vh3r7Vqz5RWV/HDBRuas3s1N/Trxq3F9Q/59kxpbXeb0owgcyP0asIfAgdw7nXObqowZS+Dg7r1m1hZYC/QDKoETzrkSb/lK4KaqB4Gr05y+SGjbX1jM/HV7eDMjj237jxMbFcHYSwLTP8N7nfv0z/GScqa88glLPytg6uhUvntN076s4dmqtzl951y5mU0FFhGYr5/tnNtkZk8BGc65hd5j15jZZqACeNw5d9DMhgPPmFklgevx/uJMhS8ioa9dyzgmXdmLh67oyYa8o1+c/bNgXT6dWsVx64AUbhuYQo+2CXX+P/ceLeb+F9eQte8Yv7j1UsYP1jTwudKLs0SkwRWXVfD+lv28mbmbDz8roNJBerdEbk9P4fpLO9LiDNM/W/cWct8Layg8Wcb0bw1kZO/kRkweOvSKXBEJSvsKi3l77R7ezNhNTkERcdERXHdJR8YNTGFYzzZfujjNsm0FTP7zJzSPjWL2xEG6LvAZqPRFJKg551i3+whzM/NYuD6fY8XldG7djNu8s38+zj3E9+d9Smq75rxw3yA6tmrmd+SgptIXkZBRXFbBPzbvY25mHsu2FXxxcfkr0toy/a4BZ5z+kYD6fHGWiEiDiouO5BuXdeIbl3Vi79Fi5q3NA+ChK3rqQu/1TKUvIkGlQ6s4HhmV6neMJku/QkVEwohKX0QkjKj0RUTCiEpfRCSMqPRFRMKISl9EJIyo9EVEwohKX0QkjATd2zCYWQGw07vbFjjgY5z6oHXwX6jnB61DMAj2/N2cc7W+BWnQlX5VZpZRl/eSCGZaB/+Fen7QOgSDUM9/iqZ3RETCiEpfRCSMBHvpz/I7QD3QOvgv1POD1iEYhHp+IMjn9EVEpH4F+56+iIjUI19L38y6mNliM9tiZpvM7N+85Ulm9g8z2+b9m+gtNzP7g5llm9kGMxvgZ/5TzCzSzNaa2V+8+z3M7GMv/+tmFuMtj/XuZ3uPd/cz9ylm1trM5prZVm9bDAvBbfAd73too5nNMbO4YN8OZjbbzPab2cYqy876625m93rjt5nZvT7n/7X3fbTBzN42s9ZVHnvSy59lZtdWWT7WW5ZtZk80Vv7TrUOVx75nZs7M2nr3g24bnBPnnG8fQEdggHe7BfAZ0Af4FfCEt/wJ4Jfe7euBdwEDhgIf+5m/ynr8O/Aq8Bfv/hvAeO/2TGCyd/sRYKZ3ezzwut/ZvSwvAQ96t2OA1qG0DYDOQC7QrMrXf2KwbwfgSmAAsLHKsrP6ugNJwHbv30TvdqKP+a8Borzbv6ySvw+wHogFegA5QKT3kQP09L731gN9/NwG3vIuwCICrxlqG6zb4JzW2e8A1b7QC4CrgSygo7esI5Dl3X4GmFBl/BfjfMycArwPjAH+4n1DHKjyjT8MWOTdXgQM825HeePM5/wtvcK0astDaRt0BnZ7P3RR3na4NhS2A9C9Wmme1dcdmAA8U2X5l8Y1dv5qj90CvOLdfhJ4sspji7xt8sV2qWmcX+sAzAUuA3bwr9IPym1wth9BM6fv/YndH/gYaO+c+xzA+7edN+zUD/cped4yP/0O+A+g0rvfBjjinCv37lfN+EV+7/Gj3ng/9QQKgBe8KarnzCyBENoGzrk9wG+AXcDnBL6umYTWdjjlbL/uQbc9qrifwJ4xhFB+M7sR2OOcW1/toZBZhzMJitI3s+bAW8BjzrnCMw2tYZlvpx+Z2Q3AfudcZtXFNQx1dXjML1EE/ryd4ZzrDxQRmFY4naBbB2/e+yYC0wadgATguhqGBvN2qM3pMgflupjZD4By4JVTi2oYFnT5zSwe+AHw/2p6uIZlQbcOtfG99M0smkDhv+Kcm+ct3mdmHb3HOwL7veV5BObaTkkB8hsraw1GADea2Q7gNQJTPL8DWpvZqYvOV834RX7v8VbAocYMXIM8IM8597F3fy6BXwKhsg0ArgJynXMFzrkyYB4wnNDaDqec7dc96LaHdyDzBuAu5813EDr5exHYeVjv/VynAJ+YWQdCZx3OyO+zdwx4HtjinPttlYcWAqeOgN9LYK7/1PJ7vKPoQ4Gjp/4U9oNz7knnXIpzrjuBA4IfOOfuAhYD47xh1fOfWq9x3nhf9wicc3uB3WZ2gbfoa8BmQmQbeHYBQ80s3vueOrUOIbMdqjjbr/si4BozS/T+4rnGW+YLMxsL/Cdwo3PuRJWHFgLjvTOnegBpwGpgDZDmnWkVQ+DnaGFj5z7FOfepc66dc66793OdR+Bkk72EyDaolZ8HFIDLCfwZtAFY531cT2B+9X1gm/dvkjfegGkEjvZ/CqT7fVCkyrqM4l9n7/Qk8A2dDbwJxHrL47z72d7jPf3O7eXqB2R422E+gTMQQmobAD8BtgIbgT8ROEskqLcDMIfAMYgyAuXywLl83QnMnWd7H/f5nD+bwPz2qZ/nmVXG/8DLnwVcV2X59QTO3MsBfuD3Nqj2+A7+dSA36LbBuXzoFbkiImHE9zl9ERFpPCp9EZEwotIXEQkjKn0RkTCi0hcRCSMqfRGRMKLSFxEJIyp9EZEw8v8BwgYMaTTGU8IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(nodes[1:7], num_node_scores[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1fc49c19e8>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(nodes[:39], node_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Epoch: 10/10 - 33741/33741 - loss: 0.6686'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = cross_validate(network, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66299895262162778"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Epoch: 10/10 - 28113/28113 - loss: 0.6789'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "mse = network_1.train(X_train, y_train, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = network_1.feedforward(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.275886  ],\n",
       "       [ 3.64692452],\n",
       "       [ 4.04033271],\n",
       "       ..., \n",
       "       [ 4.11634062],\n",
       "       [ 3.78876073],\n",
       "       [ 4.24586747]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66509203631662694"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((y_test - predicted)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
